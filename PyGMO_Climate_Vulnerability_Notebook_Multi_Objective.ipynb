{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AgatheMommeja/ClimateCommunity-project/blob/main/PyGMO_Climate_Vulnerability_Notebook_Multi_Objective.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d9bb053",
      "metadata": {
        "id": "2d9bb053"
      },
      "source": [
        "### Part 1: Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "241fd32b",
      "metadata": {
        "id": "241fd32b"
      },
      "source": [
        "Import libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93d248c7",
      "metadata": {
        "id": "93d248c7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import pygmo as pg\n",
        "import random\n",
        "import rasterio\n",
        "import shapely\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0d7d10f",
      "metadata": {
        "id": "d0d7d10f"
      },
      "outputs": [],
      "source": [
        "from rasterstats import zonal_stats\n",
        "from rasterio import features\n",
        "from rasterio import features\n",
        "from rasterio.enums import MergeAlg\n",
        "from rasterio.plot import show\n",
        "from numpy import float64\n",
        "from scipy.signal import convolve2d\n",
        "from pygmo import hypervolume"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61e1a18d",
      "metadata": {
        "id": "61e1a18d"
      },
      "source": [
        "Set the random seed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2fae2c7",
      "metadata": {
        "id": "b2fae2c7"
      },
      "outputs": [],
      "source": [
        "random.seed(1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b21f4f3c",
      "metadata": {
        "id": "b21f4f3c"
      },
      "source": [
        "Set names to filepaths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d54c1d9",
      "metadata": {
        "id": "0d54c1d9"
      },
      "outputs": [],
      "source": [
        "# specify file path to the temperature data\n",
        "temperature_raster_path = 'input_data/LST_thehague_average_raster.tif'\n",
        "\n",
        "# specify file path to the rooftop data\n",
        "buildings_shapefile_path = 'input_data/Platte_daken_classificatie.shp'\n",
        "\n",
        "# specify file path to the administrative boundary data\n",
        "admin_boundaries_shapefile_path = 'input_data/DenHaagPC5.shp'\n",
        "\n",
        "# specify file path to the indicator data\n",
        "cbs_data_PC5_path = 'input_data/pc5_2020_vol.xlsx'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08908e66",
      "metadata": {
        "id": "08908e66"
      },
      "source": [
        "Read in data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba837f43",
      "metadata": {
        "id": "ba837f43"
      },
      "outputs": [],
      "source": [
        "# read in administrative boundary data\n",
        "admin_units = gpd.read_file(admin_boundaries_shapefile_path)\n",
        "\n",
        "# read in rooftop data\n",
        "building_rooftops_unfiltered = gpd.read_file(buildings_shapefile_path)\n",
        "\n",
        "# read in social indicator data\n",
        "cbs_data_PC5 = pd.read_excel(cbs_data_PC5_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b6a0f04",
      "metadata": {
        "id": "0b6a0f04"
      },
      "source": [
        "Drop unnecesary columns from PC5 shapefile."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "410931e1",
      "metadata": {
        "id": "410931e1"
      },
      "outputs": [],
      "source": [
        "admin_units_cols_to_keep = ['PC5','geometry']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9cf882b",
      "metadata": {
        "id": "d9cf882b"
      },
      "outputs": [],
      "source": [
        "admin_units = admin_units[admin_units_cols_to_keep]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56e6f63c",
      "metadata": {
        "id": "56e6f63c"
      },
      "source": [
        "Merge shapefile with CBS data based on postal code 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "215387aa",
      "metadata": {
        "id": "215387aa"
      },
      "outputs": [],
      "source": [
        "admin_units_merged = admin_units.merge(cbs_data_PC5, on='PC5', how='inner')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2736d5d5",
      "metadata": {
        "id": "2736d5d5"
      },
      "source": [
        "Modify the data so NaNs are taken out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "601fd32d",
      "metadata": {
        "id": "601fd32d"
      },
      "outputs": [],
      "source": [
        "admin_units_merged = admin_units_merged.applymap(lambda x: 0 if x == -99997 else x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "563b2d5c",
      "metadata": {
        "id": "563b2d5c"
      },
      "source": [
        "Calculate area for all rooftops."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4348875",
      "metadata": {
        "id": "e4348875"
      },
      "outputs": [],
      "source": [
        "# Calculate total rooftop area and green rooftop area for each building\n",
        "building_rooftops_unfiltered['rooftop_area'] = building_rooftops_unfiltered.area"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82ea8251",
      "metadata": {
        "id": "82ea8251"
      },
      "source": [
        "Define function to filter dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97dea323",
      "metadata": {
        "id": "97dea323"
      },
      "outputs": [],
      "source": [
        "def filter_dataframe(df, cols_to_select, flatness_score, threshold):\n",
        "\n",
        "    # Select rows where column A is higher than the threshold\n",
        "    mask = df[flatness_score] > threshold\n",
        "    df_filtered = df.loc[mask]\n",
        "\n",
        "    # Select only the specified columns from filtered dataframe\n",
        "    df_selected = df_filtered.loc[:, cols_to_select]\n",
        "\n",
        "    # return the dataframe that contains only the buildings that are flat enough for green roofs and keep only relevant columns\n",
        "    return df_selected"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c48549c9",
      "metadata": {
        "id": "c48549c9"
      },
      "source": [
        "Specify input parameters to clean building rooftop dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f5470f6",
      "metadata": {
        "id": "3f5470f6"
      },
      "outputs": [],
      "source": [
        "# Specify input parameters for the filter dataframe function\n",
        "building_rooftop_columns = ['platdak_in','rooftop_area','geometry']\n",
        "gr_flatness_score_column = 'platdak_in'\n",
        "gr_threshold = 60"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29b536a2",
      "metadata": {
        "id": "29b536a2"
      },
      "source": [
        "Create filtered dataframe running the filter dataframe function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0911304",
      "metadata": {
        "id": "d0911304"
      },
      "outputs": [],
      "source": [
        "building_rooftops = filter_dataframe(building_rooftops_unfiltered,\n",
        "                                     building_rooftop_columns,\n",
        "                                     gr_flatness_score_column,\n",
        "                                     gr_threshold)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f1d1aae",
      "metadata": {
        "id": "8f1d1aae"
      },
      "source": [
        "Open the temperature raster and convert to array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10b024e6",
      "metadata": {
        "id": "10b024e6"
      },
      "outputs": [],
      "source": [
        "# convert the temperature raster to an array\n",
        "with rasterio.open(temperature_raster_path) as src:\n",
        "    temp_array = src.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec11cdb9",
      "metadata": {
        "id": "ec11cdb9"
      },
      "source": [
        "Define function to create array that represents spatial configurations of green roofs. This is only done to be able to do test runs for the separate objective functions. This has no function within the optimization algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0193d532",
      "metadata": {
        "id": "0193d532"
      },
      "outputs": [],
      "source": [
        "def create_array(p):\n",
        "    return np.random.choice([0, 1], size=building_rooftops.shape[0], p=[1-p, p])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd4e4131",
      "metadata": {
        "id": "fd4e4131"
      },
      "source": [
        "Create spatial configuration of green roofs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2327443c",
      "metadata": {
        "id": "2327443c"
      },
      "outputs": [],
      "source": [
        "array_gr = create_array(0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49fd14aa",
      "metadata": {
        "id": "49fd14aa"
      },
      "source": [
        "### Part 2: Define Objective Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b30a16d4",
      "metadata": {
        "id": "b30a16d4"
      },
      "source": [
        "Define function to evaluate temperate reduction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdfa9d57",
      "metadata": {
        "id": "fdfa9d57"
      },
      "outputs": [],
      "source": [
        "def temperature_reduction_function(selected_rooftops):\n",
        "\n",
        "        # add array to buiding rooftops dataframe to specify which rooftop has a green roof\n",
        "        building_rooftops_assign = building_rooftops.assign(green_roof=selected_rooftops)\n",
        "\n",
        "        # select only the rooftops that have been assigned a green roof\n",
        "        green_rooftops = building_rooftops_assign.loc[building_rooftops_assign['green_roof'] == 1]\n",
        "\n",
        "        # create tuples of geometry to assign each green roof geometry with a value that is supposed to be burned into the raster.\n",
        "        geom_value_gr = ((geom,value) for geom, value in zip(green_rooftops.geometry, green_rooftops['rooftop_area']))\n",
        "\n",
        "        # open temperature raster\n",
        "        temp_raster = rasterio.open(temperature_raster_path)\n",
        "\n",
        "        # rasterize vector using the shape and transform data of the origincal temperature raster and burn green areas into raster as raster values\n",
        "        green_roof_array = features.rasterize(geom_value_gr,\n",
        "                                    out_shape = temp_raster.shape,\n",
        "                                    transform = temp_raster.transform,\n",
        "                                    all_touched = True,\n",
        "                                    fill = 0,   # background value\n",
        "                                    merge_alg = MergeAlg.replace,\n",
        "                                    dtype = float64)\n",
        "\n",
        "        # convert the temperature raster to an array\n",
        "        with rasterio.open(temperature_raster_path) as src:\n",
        "            temp_array = src.read()\n",
        "\n",
        "        # select only the cells of the raster that are above 20 in the original raster\n",
        "        non_zero_original_temp = temp_array > 20\n",
        "\n",
        "        # calculate the average temperature of the origincal raster for all values above 20 degrees celsius\n",
        "        avg_temp_non_zero_original = np.mean(temp_array[non_zero_original_temp])\n",
        "\n",
        "        # create a Gaussian kernel that represents the diminishing effect\n",
        "        def gaussian_kernel(size, sigma):\n",
        "            x, y = np.mgrid[-size//2 + 1:size//2 + 1, -size//2 + 1:size//2 + 1]\n",
        "            g = np.exp(-((x**2 + y**2)/(2.0 * sigma**2)))\n",
        "            return g / g.sum()\n",
        "\n",
        "        kernel_size = 7\n",
        "        kernel_sigma = 2\n",
        "        kernel = gaussian_kernel(kernel_size, kernel_sigma)\n",
        "\n",
        "        # convolve the green_roof_raster with the kernel\n",
        "        convolved_green_roof_array = convolve2d(green_roof_array, kernel, mode='same', boundary='fill', fillvalue=0)\n",
        "\n",
        "        # Assume original_raster is your original green roof raster and convolved_raster is the result of the convolution\n",
        "        restored_green_roof_array = np.where((green_roof_array > 0) & (green_roof_array > convolved_green_roof_array), green_roof_array, convolved_green_roof_array)\n",
        "\n",
        "        # multiply the convolved raster with the cooling factor\n",
        "        final_cooling_effect = restored_green_roof_array * 0.0004\n",
        "\n",
        "        # compute the convolved cooling effect with maximum of 4 degrees celsius\n",
        "        final_cooling_effect_capped = np.where(final_cooling_effect > 4, 4, final_cooling_effect)\n",
        "\n",
        "        # compute the new_temperature_raster_kernel by subtracting the cooling_effect_raster from temperature_raster\n",
        "        new_temperature_raster = temp_array - final_cooling_effect_capped\n",
        "\n",
        "        # select only the cells of the raster that are above 20 in the new raster\n",
        "        non_zero_new_temp = new_temperature_raster > 20\n",
        "\n",
        "        # calculate the average temperature of the new raster for all values above 20 degrees celsius\n",
        "        avg_temp_non_zero_new = np.mean(new_temperature_raster[non_zero_new_temp])\n",
        "\n",
        "        # calculate overall temperature reduction across entire raster\n",
        "        temperature_reduction = avg_temp_non_zero_original - avg_temp_non_zero_new\n",
        "\n",
        "        def compute_average_above_zero(arr):\n",
        "                filtered_vals = arr[arr > 0]\n",
        "                if len(filtered_vals) == 0:\n",
        "                    return None  # No values greater than 0 found\n",
        "                else:\n",
        "                    return np.mean(filtered_vals)\n",
        "\n",
        "        # calculate the average cooling effect for all the cells that have been cooled to some extent\n",
        "        cooling_effect_average = compute_average_above_zero(final_cooling_effect_capped)\n",
        "\n",
        "        return cooling_effect_average"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1240c740",
      "metadata": {
        "id": "1240c740"
      },
      "source": [
        "Define function to evaluate coverage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f798baf2",
      "metadata": {
        "id": "f798baf2"
      },
      "outputs": [],
      "source": [
        "def calculate_vulnerability_points(building_rooftops, admin_units_merged, selected_rooftops):\n",
        "      # add array to buiding rooftops dataframe to specify which rooftop has a green roof\n",
        "    building_rooftops_assign = building_rooftops.assign(green_roof=selected_rooftops)\n",
        "\n",
        "    # Calculate green rooftop area\n",
        "    building_rooftops['green_rooftop_area'] = building_rooftops_assign['rooftop_area'] * building_rooftops_assign['green_roof']\n",
        "\n",
        "    # Spatially join building rooftops to administrative boundaries\n",
        "    admin_units_buildings = gpd.sjoin(admin_units_merged, building_rooftops, predicate='intersects')\n",
        "\n",
        "    # Group by administrative boundary and calculate total rooftop area and green rooftop area\n",
        "    admin_units_buildings_grouped = admin_units_buildings.groupby('PC5').agg({'rooftop_area': 'sum', 'green_rooftop_area': 'sum', 'geometry': 'first'})\n",
        "\n",
        "    # Calculate the green roof coverage percentage within each administrative boundary\n",
        "    admin_units_buildings_grouped['coverage_pct'] = admin_units_buildings_grouped['green_rooftop_area'] / admin_units_buildings_grouped['rooftop_area']\n",
        "\n",
        "    # Merge admin_boundaries columns to admin_boundaries_with_rooftops_grouped dataframe\n",
        "    admin_units_df = admin_units_merged[[\"PC5\",\"INHABITANTS\",\"PEOP_SOC_SEC_BELOW_AOW_AGE\"]].merge(admin_units_buildings_grouped, on='PC5')\n",
        "\n",
        "    # Calculate covered vulnerability points for single indicator\n",
        "    admin_units_df['cov_vul_points'] = admin_units_df['coverage_pct'] * admin_units_df['INHABITANTS'] * (admin_units_df['PEOP_SOC_SEC_BELOW_AOW_AGE']/admin_units_df['INHABITANTS'])\n",
        "\n",
        "    # Calculate total vulnerability points for single indicator\n",
        "    admin_units_df['tot_vul_points'] = admin_units_df['INHABITANTS'] * (admin_units_df['PEOP_SOC_SEC_BELOW_AOW_AGE']/admin_units_df['INHABITANTS'])\n",
        "\n",
        "    # Calculate level of coverage of vulnerability points\n",
        "    vulnerability_points_covered = admin_units_df['cov_vul_points'].sum()\n",
        "\n",
        "    # Calculate level of coverage of vulnerability points\n",
        "    vulnerability_points_total = admin_units_df['tot_vul_points'].sum()\n",
        "\n",
        "    vulnerability_coverage = vulnerability_points_covered / vulnerability_points_total\n",
        "\n",
        "    return vulnerability_coverage"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc293b5b",
      "metadata": {
        "id": "fc293b5b"
      },
      "source": [
        "### Part 3: Define Optimization Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4149d31",
      "metadata": {
        "id": "f4149d31"
      },
      "source": [
        "Create vector to simulate configuration to feed optimization algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3765a5b1",
      "metadata": {
        "id": "3765a5b1"
      },
      "outputs": [],
      "source": [
        "def encode(x, num_buildings):\n",
        "    indices = np.argsort(x)[:num_buildings * 2 // 4]\n",
        "    selected_rooftops = np.zeros(num_buildings, dtype=int)\n",
        "    selected_rooftops[indices] = 1\n",
        "    return selected_rooftops"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b599d424",
      "metadata": {
        "id": "b599d424"
      },
      "source": [
        "Define optimization problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69c5b448",
      "metadata": {
        "id": "69c5b448"
      },
      "outputs": [],
      "source": [
        "class GreenRoofProblem:\n",
        "    def __init__(self, building_rooftops, admin_units_merged, num_rooftops=building_rooftops.shape[0], num_green_roofs=None, heat_stress_reduction_function=None, vulnerable_coverage_function=None):\n",
        "        self.num_rooftops = num_rooftops\n",
        "        self.num_green_roofs = num_green_roofs if num_green_roofs else num_rooftops * 2 // 4\n",
        "        self.building_rooftops = building_rooftops\n",
        "        self.admin_units_merged = admin_units_merged\n",
        "        self.heat_stress_reduction_function = heat_stress_reduction_function\n",
        "        self.calculate_vulnerability_points = calculate_vulnerability_points\n",
        "\n",
        "    def fitness(self, x):\n",
        "        selected_rooftops = encode(x, self.num_rooftops)\n",
        "\n",
        "        heat_stress_reduction = self.heat_stress_reduction_function(selected_rooftops)\n",
        "\n",
        "        coverage_score = self.calculate_vulnerability_points(self.building_rooftops, self.admin_units_merged, selected_rooftops)\n",
        "\n",
        "        return [-heat_stress_reduction, -coverage_score]  # Maximize both objectives\n",
        "\n",
        "    def get_bounds(self):\n",
        "        return ([0] * self.num_rooftops, [1] * self.num_rooftops)\n",
        "\n",
        "    def get_nobj(self):\n",
        "        return 2\n",
        "\n",
        "    def get_name(self):\n",
        "        return \"Green Roof Placement Problem\"\n",
        "\n",
        "    def get_extra_info(self):\n",
        "        return f\"Number of rooftops: {self.num_rooftops}\\nNumber of green roofs: {self.num_green_roofs}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1049d2bb",
      "metadata": {
        "id": "1049d2bb"
      },
      "source": [
        "Create an instance of the GreenRoofProblem class, which is a user-defined problem (UDP) in PyGMO terminology. The resulting UDP object represents the optimization problem, including the decision variables (the configuration of green roofs), the objectives (heat stress reduction and vulnerable population coverage), and the constraints (eg. half of the rooftops must have green roofs). This object can be used to create a PyGMO problem object, which is then used to initialize a population object and solve the problem using an optimization algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fe7c389",
      "metadata": {
        "id": "4fe7c389"
      },
      "outputs": [],
      "source": [
        "# Problem definition\n",
        "udp = GreenRoofProblem(building_rooftops, admin_units_merged,\n",
        "                       heat_stress_reduction_function=temperature_reduction_function,\n",
        "                       vulnerable_coverage_function=calculate_vulnerability_points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "442b22e4",
      "metadata": {
        "id": "442b22e4"
      },
      "outputs": [],
      "source": [
        "problem = pg.problem(udp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5514a9fc",
      "metadata": {
        "id": "5514a9fc"
      },
      "source": [
        "The following 2 lines of code set up the NSGA-II algorithm with 50 generations and a verbosity level of 2, ready to be used for evolving a population and solving the optimization problem.\n",
        "\n",
        "- **pg.algorithm(pg.nsga2(gen=50, seed=1234))** creates an instance of the NSGA-II algorithm wrapped in a pg.algorithm object, which is required for using the algorithm in PyGMO. NSGA-II is a popular multi-objective evolutionary algorithm used for solving optimization problems with multiple conflicting objectives.\n",
        "\n",
        "- **algo.set_verbosity(2)** sets the verbosity level of the algorithm. The verbosity level determines how much information the algorithm provides during the optimization process. A verbosity level of 2 means the algorithm will print a log every 2 generations, giving information about the current generation, the best fitness so far, the average fitness, etc. This can be helpful for tracking the progress of the optimization process and diagnosing any potential issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c922205",
      "metadata": {
        "id": "6c922205"
      },
      "outputs": [],
      "source": [
        "# set the algorithm and the amount of generations\n",
        "algo = pg.algorithm(pg.nsga2(gen=2, seed=1234))\n",
        "algo.set_verbosity(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebebbd6a",
      "metadata": {
        "id": "ebebbd6a"
      },
      "source": [
        "The following line of code creates an instance of a PyGMO population object, which represents a group of candidate solutions for the optimization problem. The population object is initialized with two arguments:\n",
        "\n",
        "- **Problem**: This is the PyGMO problem object created earlier, which encapsulates the Green Roof Placement Problem's definition, including the objectives, constraints, and bounds. The problem object is used by the population to evaluate the fitness of individuals (candidate solutions).\n",
        "\n",
        "- **Size**: This argument sets the size of the population, which is the number of individuals (candidate solutions) it contains. In this case, the population size is set to 100, which means the algorithm will work with 100 candidate solutions simultaneously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6df7b33",
      "metadata": {
        "scrolled": true,
        "id": "a6df7b33"
      },
      "outputs": [],
      "source": [
        "# Population\n",
        "pop = pg.population(problem, size=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6f5df27",
      "metadata": {
        "id": "f6f5df27"
      },
      "source": [
        "The following lines calculate the hypervolume indicator, which is a metric used to assess the quality of a set of solutions in multi-objective optimization. The hypervolume indicator measures the volume of the space dominated by the solutions in the objective space, and it's often used to compare different Pareto fronts in multi-objective optimization.\n",
        "\n",
        "\n",
        "- **hv = hypervolume(pop)**: This line creates a hypervolume object from the final population pop after the optimization process. The hypervolume object provides methods for computing the hypervolume indicator and related metrics.\n",
        "\n",
        "- **ref_point = hv.refpoint(offset = 0.1)**: This line computes a reference point for calculating the hypervolume indicator. The reference point is a point in the objective space that is worse than any solution in the population (i.e., it's dominated by all solutions). In multi-objective optimization, solutions are usually evaluated based on how much they dominate the reference point. The offset parameter adds a small margin to the reference point to ensure that it's strictly worse than all solutions.\n",
        "\n",
        "- **hv_pre_evolve = hv.compute(ref_point)**: This line computes the hypervolume indicator for the population pop with respect to the reference point ref_point. The resulting value represents the volume of the space in the objective space that is dominated by the solutions in pop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d3ec085",
      "metadata": {
        "id": "4d3ec085"
      },
      "outputs": [],
      "source": [
        "hv = hypervolume(pop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bba070fb",
      "metadata": {
        "id": "bba070fb"
      },
      "outputs": [],
      "source": [
        "ref_point = hv.refpoint(offset = 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93dba378",
      "metadata": {
        "id": "93dba378"
      },
      "outputs": [],
      "source": [
        "hv_pre_evolve = hv.compute(ref_point)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51f98a99",
      "metadata": {
        "id": "51f98a99"
      },
      "source": [
        "When you run the line pop = algo.evolve(pop), the optimization process using the NSGA-II algorithm starts, evolving the input population pop over multiple generations. After the evolve function call, the evolved population contains candidate solutions that represent better green roof configurations, aiming to maximize heat stress reduction and vulnerable population coverage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ad4fdde",
      "metadata": {
        "scrolled": true,
        "id": "4ad4fdde"
      },
      "outputs": [],
      "source": [
        "# Evolve\n",
        "pop = algo.evolve(pop)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d0d5176",
      "metadata": {
        "id": "9d0d5176"
      },
      "source": [
        "Extract information about the optimization process after it has been completed.\n",
        "\n",
        "- **uda = algo.extract(pg.nsga2)** is used to extract the underlying algorithm (in this case, NSGA-II) from the PyGMO algorithm object. The extract method returns the specific algorithm instance used inside the pg.algorithm wrapper. The returned UDA (User-Defined Algorithm) object allows you to access the methods and properties of the specific algorithm that are not part of the generic pg.algorithm interface.\n",
        "\n",
        "- **evolution_fitness_values = uda.get_log()** is used to retrieve the log of the optimization process. The get_log method of the NSGA-II algorithm returns a list of tuples, each containing information about a particular generation during the optimization process. The contents of each tuple depend on the algorithm and the verbosity level, but for NSGA-II with verbosity level 2, the tuple typically includes the generation number, the current best fitness, the average fitness, etc. This log can be useful for analyzing the evolution of the fitness values over the generations and understanding the progress of the optimization process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a875f0d",
      "metadata": {
        "id": "1a875f0d"
      },
      "outputs": [],
      "source": [
        "uda = algo.extract(pg.nsga2)\n",
        "evolution_fitness_values = uda.get_log()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfc424fa",
      "metadata": {
        "id": "bfc424fa"
      },
      "source": [
        "Store the information of the User-Defined Algorithm in a dataframe and write it to a .csv file so it can be accessed later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1a216cc",
      "metadata": {
        "id": "a1a216cc"
      },
      "outputs": [],
      "source": [
        "# Create dataframe\n",
        "evolution_fitness_values_df = pd.DataFrame(evolution_fitness_values, columns=['Verbosity', 'Runs', 'Array'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "130b9b98",
      "metadata": {
        "id": "130b9b98"
      },
      "source": [
        "Split the column array into the two different optimization objective to store their fitness values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbb9640b",
      "metadata": {
        "id": "dbb9640b"
      },
      "outputs": [],
      "source": [
        "evolution_fitness_values_df[['Temperature reduction', 'Vulnerability points covered']] = pd.DataFrame(evolution_fitness_values_df['Array'].to_list())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72af4669",
      "metadata": {
        "id": "72af4669"
      },
      "source": [
        "Drop the column array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e77c0296",
      "metadata": {
        "id": "e77c0296"
      },
      "outputs": [],
      "source": [
        "evolution_fitness_values_df.drop('Array', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ec3feb9",
      "metadata": {
        "id": "2ec3feb9"
      },
      "source": [
        "Store dataframe as .csv file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92800fe5",
      "metadata": {
        "id": "92800fe5"
      },
      "outputs": [],
      "source": [
        "evolution_fitness_values_df.to_csv('evolution_fitness_values.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e95aff3",
      "metadata": {
        "id": "1e95aff3"
      },
      "source": [
        "Calculate the hypervolume after the evolution of the population. This can provide valuable insight into how the quality of the solution set has improved through the course of the optimization process. By comparing the hypervolume before and after evolution, you can quantify the improvement in the solution set due to the optimization process. The larger the increase in hypervolume, the more the algorithm has been able to improve the solutions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "211dfd4f",
      "metadata": {
        "id": "211dfd4f"
      },
      "outputs": [],
      "source": [
        "hv = pg.hypervolume(pop)\n",
        "hv_after_evolve = hv.compute(ref_point)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00e6c897",
      "metadata": {
        "id": "00e6c897"
      },
      "outputs": [],
      "source": [
        "hv_data = {'Before': [hv_pre_evolve], 'After': [hv_after_evolve]}\n",
        "hypervolume_df = pd.DataFrame(hv_data)\n",
        "hypervolume_df.to_csv('hypervolume_values.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a569a129",
      "metadata": {
        "id": "a569a129"
      },
      "source": [
        "Create a list that stores the different arrays that represent the spatial configurations of the placements of the green roofs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d32070a5",
      "metadata": {
        "id": "d32070a5"
      },
      "outputs": [],
      "source": [
        "# encode the solutions\n",
        "encoded_solutions = [encode(pop.get_x()[i], udp.num_rooftops) for i in range(len(pop))]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4240614e",
      "metadata": {
        "id": "4240614e"
      },
      "source": [
        "Extract the fitness values from the populations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b79d1483",
      "metadata": {
        "id": "b79d1483"
      },
      "outputs": [],
      "source": [
        "# Extract the fitness values\n",
        "fitness_values = pop.get_f()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a2e6e50",
      "metadata": {
        "id": "8a2e6e50"
      },
      "source": [
        "Store the fitness values together with their corresponding spatial configurations in a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5746d16f",
      "metadata": {
        "id": "5746d16f"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame to store the results\n",
        "results_df = pd.DataFrame({'Temperature Reduction (C)': -fitness_values[:,0], 'Vulnerable Coverage': (-fitness_values[:,1]) , 'Configuration': encoded_solutions})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c202b17f",
      "metadata": {
        "id": "c202b17f"
      },
      "outputs": [],
      "source": [
        "# Convert the binary values from float to integer to make it more smaller.\n",
        "results_df['Configuration'] = results_df['Configuration'].apply(lambda x: [int(i) for i in x])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b822ad59",
      "metadata": {
        "id": "b822ad59"
      },
      "source": [
        "Store the output as .JSON file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03c08073",
      "metadata": {
        "id": "03c08073"
      },
      "outputs": [],
      "source": [
        "# Write DataFrame to CSV file\n",
        "results_df.to_json('optimization_output.json', orient='index', index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "657c3227",
      "metadata": {
        "id": "657c3227"
      },
      "source": [
        "Create a dataframe that separately stores the fitness values to be able to visualize the pareto front."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b957b565",
      "metadata": {
        "id": "b957b565"
      },
      "outputs": [],
      "source": [
        "pareto_front_df = pd.DataFrame(fitness_values, columns=['Temperature reduction', 'Vulnerability points covered'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45f1a274",
      "metadata": {
        "id": "45f1a274"
      },
      "outputs": [],
      "source": [
        "heat_stress_reduction = [-fit[0] for fit in fitness_values]\n",
        "vulnerable_coverage = [-fit[1] for fit in fitness_values]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "169ee829",
      "metadata": {
        "id": "169ee829"
      },
      "source": [
        "Plot the pareto front."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2df2a8e",
      "metadata": {
        "id": "d2df2a8e"
      },
      "outputs": [],
      "source": [
        "# Create a scatter plot\n",
        "plt.scatter(heat_stress_reduction, vulnerable_coverage, marker='o', edgecolors='k', facecolors='none')\n",
        "plt.xlabel('Heat stress reduction')\n",
        "plt.ylabel('Vulnerability points covered')\n",
        "plt.title('Pareto front')\n",
        "\n",
        "# Show the plot\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3398ee6d",
      "metadata": {
        "id": "3398ee6d"
      },
      "outputs": [],
      "source": [
        "obj_values = pop.get_f()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66b1939e",
      "metadata": {
        "id": "66b1939e"
      },
      "outputs": [],
      "source": [
        "obj_values2 = pop.get_x()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46b26aaf",
      "metadata": {
        "id": "46b26aaf",
        "outputId": "7347aaca-ff17-4f5d-c4c6-02e96fae5661"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.32235787, 0.80409172, 0.40510254, ..., 0.74386858, 0.23210128,\n",
              "        0.50377693],\n",
              "       [0.13013358, 0.73176839, 0.92483529, ..., 0.68623463, 0.97094234,\n",
              "        0.47833066],\n",
              "       [0.27178049, 0.5907202 , 0.06567685, ..., 0.79351146, 0.21561793,\n",
              "        0.66068373],\n",
              "       ...,\n",
              "       [0.13013358, 0.73759282, 0.9275513 , ..., 0.6857043 , 0.99516514,\n",
              "        0.49354768],\n",
              "       [0.32235787, 0.27659525, 0.40509691, ..., 0.74386858, 0.23736142,\n",
              "        0.50377693],\n",
              "       [0.13013358, 0.73176839, 0.92483529, ..., 0.68566633, 0.97094234,\n",
              "        0.47800725]])"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "obj_values2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a92346b0",
      "metadata": {
        "id": "a92346b0"
      },
      "outputs": [],
      "source": [
        "front_indices = pg.non_dominated_front_2d(obj_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e2120aa",
      "metadata": {
        "id": "1e2120aa",
        "outputId": "11765b41-7269-4158-9f5f-c314bdc823e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2, 1, 0], dtype=uint64)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "front_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04d456fd",
      "metadata": {
        "id": "04d456fd"
      },
      "outputs": [],
      "source": [
        "# Extract the non-dominated front individuals\n",
        "non_dominated_front = pop[front_indices]\n",
        "\n",
        "# Access the decision variables and objective values of the non-dominated front\n",
        "front_variables = non_dominated_front.get_x()\n",
        "front_objectives = non_dominated_front.get_f()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}